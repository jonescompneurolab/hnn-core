<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Parallel backends &#8212; hnn-core  documentation</title>
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="_static/gallery-rendered-html.css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="_static/js/jquery-1.11.0.min.js "></script>
<script type="text/javascript" src="_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="_static/bootstrap-3.3.7/js/bootstrap.min.js "></script>
<script type="text/javascript" src="_static/bootstrap-sphinx.js "></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html">
          hnn-core</a>
        <span class="navbar-text navbar-version pull-left"><b>0.2.dev0</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="auto_examples/index.html">Examples</a></li>
                <li><a href="api.html">API</a></li>
                <li><a href="whats_new.html">Whats new</a></li>
                <li><a href="https://github.com/jonescompneurolab/hnn-core">GitHub</a></li>
                <li><a href="roadmap.html">Roadmap</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"></ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Parallel backends</a><ul>
<li><a class="reference internal" href="#joblib">Joblib</a></li>
<li><a class="reference internal" href="#mpi">MPI</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
            
            
            
              <li class="hidden-sm">
<div id="sourcelink">
  <a href="_sources/parallel.rst.txt"
     rel="nofollow">Source</a>
</div></li>
            
          </ul>

          
<div class="navbar-form navbar-right navbar-btn dropdown btn-group-sm" style="margin-left: 20px; margin-top: 5px; margin-bottom: 5px">
  <button type="button" class="btn btn-primary navbar-btn dropdown-toggle" id="dropdownMenu1" data-toggle="dropdown">
    v0.2.dev0
    <span class="caret"></span>
  </button>
  <ul class="dropdown-menu" aria-labelledby="dropdownMenu1">
    <li><a href="https://jonescompneurolab.github.io/hnn-core/dev/index.html">Development</a></li>
    <li><a href="https://jonescompneurolab.github.io/hnn-core/stable/index.html">Stable</a></li>
    <li><a href="https://jonescompneurolab.github.io/hnn-core/v0.1/index.html">v0.1</a></li>
  </ul>
</div>


            
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          

        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <div class="section" id="parallel-backends">
<span id="parallel"></span><h1>Parallel backends<a class="headerlink" href="#parallel-backends" title="Permalink to this headline">¶</a></h1>
<p>Two options are available for making use of multiple CPU cores. The first runs multiple trials in parallel with joblib. Alternatively, you can run each trial across multiple cores to reduce the runtime.</p>
<div class="section" id="joblib">
<h2>Joblib<a class="headerlink" href="#joblib" title="Permalink to this headline">¶</a></h2>
<p>This is the default backend and will execute multiple trials at the same time, with each trial running on a separate core in “embarrassingly parallel” execution. Note that with only 1 trial, there will be no parallelism.</p>
<p><strong>Dependencies</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ pip install joblib
</pre></div>
</div>
<p><strong>Usage</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">hnn_core</span> <span class="kn">import</span> <span class="n">JoblibBackend</span>

<span class="c1"># set n_jobs to the number of trials to run in parallel with Joblib (up to number of cores on system)</span>
<span class="k">with</span> <span class="n">JoblibBackend</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="n">dpls</span> <span class="o">=</span> <span class="n">simulate_dipole</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="mpi">
<h2>MPI<a class="headerlink" href="#mpi" title="Permalink to this headline">¶</a></h2>
<p>This backend will use MPI (Message Passing Interface) on the system to split neurons across CPU cores (processors) and reduce the simulation time as more cores are used.</p>
<p><strong>Linux Dependencies</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ sudo apt-get install libopenmpi-dev openmpi-bin
$ pip install mpi4py psutil
</pre></div>
</div>
<p><strong>MacOS Dependencies</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ conda install -y openmpi mpi4py
$ pip install psutil
</pre></div>
</div>
<p><strong>MacOS Environment</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ export LD_LIBRARY_PATH=${CONDA_PREFIX}/lib
</pre></div>
</div>
<p>Alternatively, run the commands below will avoid needing to run the export command every time a new shell is opened:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ cd ${CONDA_PREFIX}
$ mkdir -p etc/conda/activate.d etc/conda/deactivate.d
$ echo &quot;export OLD_LD_LIBRARY_PATH=\$LD_LIBRARY_PATH&quot; &gt;&gt; etc/conda/activate.d/env_vars.sh
$ echo &quot;export LD_LIBRARY_PATH=\$LD_LIBRARY_PATH:\${CONDA_PREFIX}/lib&quot; &gt;&gt; etc/conda/activate.d/env_vars.sh
$ echo &quot;export LD_LIBRARY_PATH=\$OLD_LD_LIBRARY_PATH&quot; &gt;&gt; etc/conda/deactivate.d/env_vars.sh
$ echo &quot;unset OLD_LD_LIBRARY_PATH&quot; &gt;&gt; etc/conda/deactivate.d/env_vars.sh
</pre></div>
</div>
<p><strong>Test MPI</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ mpiexec -np 2 nrniv -mpi -python -c &#39;from neuron import h; from mpi4py import MPI; \
                                       print(&quot;Hello from proc %d&quot; % MPI.COMM_WORLD.Get_rank()); \
                                           h.quit()&#39;
numprocs=2
NEURON -- VERSION 7.7.2 7.7 (2b7985ba) 2019-06-20
Duke, Yale, and the BlueBrain Project -- Copyright 1984-2018
See http://neuron.yale.edu/neuron/credits

Hello from proc 0
Hello from proc 1
</pre></div>
</div>
<p>Verifies that MPI, NEURON, and Python are all working together.</p>
<p><strong>Usage</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">hnn_core</span> <span class="kn">import</span> <span class="n">MPIBackend</span>

<span class="c1"># Set n_procs to the number of processors MPI can use (up to number of cores on system)</span>
<span class="c1"># A different launch command can be specified for MPI distributions other than openmpi</span>
<span class="k">with</span> <span class="n">MPIBackend</span><span class="p">(</span><span class="n">n_procs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">mpi_cmd</span><span class="o">=</span><span class="s1">&#39;mpiexec&#39;</span><span class="p">):</span>
    <span class="n">dpls</span> <span class="o">=</span> <span class="n">simulate_dipole</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Notes for contributors</strong>:</p>
<p>MPI parallelization with NEURON requires that the simulation be launched with the <code class="docutils literal notranslate"><span class="pre">nrniv</span></code> binary
from the command-line. The <code class="docutils literal notranslate"><span class="pre">mpiexec</span></code> command is used to launch multiple <code class="docutils literal notranslate"><span class="pre">nrniv</span></code> processes which
communicate via MPI. This is done using <code class="docutils literal notranslate"><span class="pre">subprocess.Popen()</span></code> in <code class="docutils literal notranslate"><span class="pre">MPIBackend.simulate()</span></code> to
launch parallel child processes (<code class="docutils literal notranslate"><span class="pre">MPISimulation</span></code>) to carry out the simulation.
The communication sequence between <code class="docutils literal notranslate"><span class="pre">MPIBackend</span></code> and <code class="docutils literal notranslate"><span class="pre">MPISimulation</span></code> is outlined below.</p>
<ol class="arabic simple">
<li><p>In order to pass the network to simulate from <code class="docutils literal notranslate"><span class="pre">MPIBackend</span></code>, the child <code class="docutils literal notranslate"><span class="pre">MPISimulation</span></code>
processes’ <code class="docutils literal notranslate"><span class="pre">stdin</span></code> is used. The ready-to-use <em class="xref py py-obj">Network</em> object is base64 encoded and pickled
before being written to the child processes’ <code class="docutils literal notranslate"><span class="pre">stdin</span></code> by way of a Queue in a non-blocking way.
See how it is <a class="reference external" href="https://github.com/mne-tools/mne-python/blob/148de1661d5e43cc88d62e27731ce44e78892951/mne/utils/misc.py#L124-L132">used in MNE-Python</a>. The data is marked by start and end signals that are used
to extract the pickled net object. After being unpickled, the parallel simulation begins.</p></li>
<li><p>Output from the simulation (either to <code class="docutils literal notranslate"><span class="pre">stdout</span></code> or <code class="docutils literal notranslate"><span class="pre">stderr</span></code>) is communicated back
to <code class="docutils literal notranslate"><span class="pre">MPIBackend</span></code>, where it will be printed to the console. Typical output at this point
would be simulation progress messages as well as any MPI warnings/errors during the simulation.</p></li>
<li><p>Once the simulation has completed, the rank 0 of the child process sends back the simulation data
by base64 encoding and and pickling the data object. It also adds markings for the start and end
of the encoded data, including the expected length of data (in bytes) in the end of data marking.
Finally rank 0 writes the whole string with markings and encoded data to <code class="docutils literal notranslate"><span class="pre">stderr</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">MPIBackend</span></code> will look for these markings to know that data is being sent (and will not
print this). It will verify the length of data it receives, printing a
<code class="docutils literal notranslate"><span class="pre">UserWarning</span></code> if the data length received doesn’t match the length part of the marking.</p></li>
<li><p>To signal that the child process should terminate, <code class="docutils literal notranslate"><span class="pre">MPIBackend</span></code> sends a signal to the child
proccesses’ <code class="docutils literal notranslate"><span class="pre">stdin</span></code>. After sending the simulation data, rank 0 waits for this completion signal
before continuing and letting all ranks of the MPI process exit successfully.</p></li>
<li><p>At this point, <code class="docutils literal notranslate"><span class="pre">MPIBackend.simulate()</span></code> decodes and unpickles the data, populates the network’s
CellResponse object, and returns the simulation dipoles to the caller.</p></li>
</ol>
<p>It is important that <code class="docutils literal notranslate"><span class="pre">flush()</span></code> is used whenever data is written to stdin or stderr to ensure that the signal will immediately be available for reading by the other side.</p>
<p>Tests for parallel backends utilize a special <code class="docutils literal notranslate"><span class="pre">&#64;pytest.mark.incremental</span></code> decorator (defined in <code class="docutils literal notranslate"><span class="pre">conftest.py</span></code>) that causes a test failure to skip subsequent tests in the incremental block. For example, if a test running a simple MPI simulation fails, subsequent tests that compare simulation output between different backends will be skipped. These types of failures will be marked as a failure in CI.</p>
</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2021, HNN Developers.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.3.<br/>
    </p>
  </div>
</footer>
  </body>
</html>